{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "687ab825",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Scraping Job Data\n",
    "\n",
    "This project focuses on collecting job-related data from Glassdoor using Selenium and BeautifulSoup. The data includes job titles, descriptions, and other relevant information to help analyze job market trends."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb3c22f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f15c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b914030",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Configure Selenium WebDriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102a2068",
   "metadata": {},
   "outputs": [],
   "source": [
    "chrome_options = Options()\n",
    "chrome_options.add_argument('--headless')\n",
    "chrome_options.add_argument('--no-sandbox')\n",
    "chrome_options.add_argument('--disable-dev-shm-usage')\n",
    "chrome_options.add_argument(\"--disable-gpu\") \n",
    "chrome_options.add_argument(\"start-maximized\")\n",
    "chrome_options.add_argument(\"disable-infobars\")\n",
    "chrome_options.add_argument(\"--disable-extensions\")\n",
    "chrome_options.add_argument(\n",
    "    \"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c12343e-421a-41dc-9e52-fbad4b93ba2b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Part A: Scraping Job URLs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72beb63b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 1. Define Functions for Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2927f8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_jobs(driver):\n",
    "    \"\"\"Extract Job URLs from the current page.\"\"\"\n",
    "    urls = []\n",
    "    \n",
    "    try:\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        \n",
    "        json_ld = soup.find('script', type='application/ld+json')\n",
    "        if json_ld:\n",
    "            data = json.loads(json_ld.string)\n",
    "            job_list = data.get('itemListElement', [])\n",
    "            for job in job_list :\n",
    "                urls.append(job.get('url'))\n",
    "        else:\n",
    "            print(\"No JSON-LD found!\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing jobs: {e}\")\n",
    "    \n",
    "    return urls\n",
    "\n",
    "def auto(company, driver):\n",
    "    \"\"\"Automate the scraping process for a given company.\"\"\"\n",
    "    company = company.replace(\" \",\"-\")\n",
    "    url = f'https://www.glassdoor.com/Job/united-states-{company}-jobs.htm'\n",
    "    driver.get(url)\n",
    "    \n",
    "    wait = WebDriverWait(driver, 10)\n",
    "    current_urls = []\n",
    "    urls = extract_jobs(driver)\n",
    "    current_urls.extend(urls)\n",
    "    \n",
    "    return current_urls, driver"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf50dda",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 2. Main Scraping Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3e6128",
   "metadata": {},
   "outputs": [],
   "source": [
    "companies_name_followers = pd.read_csv(\"companies_name_by_followers.csv\")\n",
    "companies_name_list = companies_name_followers[\"name\"].tolist()\n",
    "\n",
    "urls_list = []\n",
    "for company in tqdm(companies_name_list, desc='Scraping Companies'):\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "    current_urls,driver = auto(comp,driver)\n",
    "    urls_list += current_urls\n",
    "    driver.quit()\n",
    "print(f'Total URLs collected: {len(urls_list)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef26500d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 3. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e78e346",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_job_urls = pd.DataFrame({\"Job_URL\":urls_list})\n",
    "df_job_urls.to_csv('job_urls.csv', index=False)\n",
    "print('Saved to job_urls.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa82fcb-891a-4a34-bb5b-6c45b36daa09",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Part B: Scraping Job Descriptions from the Job URLs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf73694-b07f-4e40-a608-e8db194896dd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 1. Define Functions for Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74d4432-080f-4247-b3f6-99225670f0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_job_description(url,driver):\n",
    "    \"\"\"Extract job desrcriptions from the current job page.\"\"\"\n",
    "\n",
    "    driver.get(url)  \n",
    "    wait = WebDriverWait(driver, 10) \n",
    "    \n",
    "    # Handle 'Show More' button if it exists\n",
    "    try:\n",
    "        show_more_button = wait.until(EC.element_to_be_clickable((By.XPATH, \"//button[span[text()='Show more']]\")))\n",
    "        driver.execute_script(\"arguments[0].scrollIntoView(true);\", show_more_button)\n",
    "        driver.execute_script(\"arguments[0].click();\", show_more_button)  # Perform the click via JavaScript\n",
    "        time.sleep(2)  \n",
    "    except Exception as e:\n",
    "        print(f\"No 'Show More' button or an error occurred on URL {url}: {e}\")\n",
    "    \n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    \n",
    "    json_ld = soup.find(\"script\", type=\"application/ld+json\")\n",
    "    \n",
    "    if json_ld:\n",
    "        data = json.loads(json_ld.string)  \n",
    "        job_name = data.get(\"title\", \"N/A\")  \n",
    "        job_description = data.get(\"description\", \"N/A\") \n",
    "        return url, job_name, job_description, driver\n",
    "    else:\n",
    "        print(f\"No JSON-LD found on URL: {url}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcac13c3-8a6c-437e-8387-e163977cde8f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 2. Main Scraping Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a3558e-059b-4a96-8d17-1ab7cab708e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_urls = df_job_urls[\"Job_URL\"].tolist()\n",
    "job_description_dict = {\"Job_Url\":[], \"Job_Name\":[], \"Job_Description\":[]}\n",
    "\n",
    "for url in tqdm(job_urls, desc=\"Scraping job description\", unit=\"job url\"):\n",
    "    \n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "    result = auto_job_description(url,driver)\n",
    "    if result == None:\n",
    "        continue\n",
    "    current_url, current_name, current_description ,driver = result\n",
    "    driver.quit()\n",
    "    \n",
    "    job_desc_dict[\"Job_Url\"].append(current_url)\n",
    "    job_desc_dict[\"Job_Name\"].append(current_name)\n",
    "    job_desc_dict[\"Job_Description\"].append(current_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08ef80a-4a0d-4f08-af74-39014d029c3e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 3. Clean description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29867e4c-d1e0-42c7-8f6b-24165d971d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\" Clean the scraped job description\"\"\" \n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    text_content = soup.get_text(separator=\"\\n\")\n",
    "    cleaned_text = re.sub(r'\\n+', ' ', text_content)\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7891b78c-f2dd-4bd6-aa9c-6f228c59d22f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 4. Apply clean Data & Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c32117-13f5-4715-8f83-0199c4b6790f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_job_descriptions = pd.DataFrame(job_description_dict)\n",
    "df_job_descriptions[\"Job_Description\"] = df_job_descriptions[\"Job_Description\"].apply(lambda x: clean_text(x))\n",
    "df_job_descriptions.to_csv('job_descriptions.csv', index=False)\n",
    "print('Saved to job_descriptions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d226a437-8af9-49f4-8c89-bc0f23c16ff1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
